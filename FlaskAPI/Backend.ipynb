{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ccc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://192.168.29.151:8000\n",
      "Press CTRL+C to quit\n",
      "192.168.29.74 - - [10/Mar/2024 03:45:42] \"POST /upload_and_transcribe HTTP/1.1\" 308 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.29.74 - - [10/Mar/2024 03:46:07] \"POST /upload_and_transcribe/ HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n",
      "Waiting for server processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.29.74 - - [10/Mar/2024 04:37:19] \"POST /upload_and_transcribe/ HTTP/1.1\" 200 -\n",
      "192.168.29.74 - - [10/Mar/2024 04:38:38] \"POST /generate_flashcards/ HTTP/1.1\" 404 -\n",
      "192.168.29.74 - - [10/Mar/2024 04:38:55] \"POST /generate_flashcards/ HTTP/1.1\" 404 -\n",
      "192.168.29.74 - - [10/Mar/2024 04:38:55] \"POST /generate_flashcards/ HTTP/1.1\" 404 -\n",
      "192.168.29.74 - - [10/Mar/2024 04:44:01] \"POST /generate_flashcards/ HTTP/1.1\" 404 -\n",
      "192.168.29.74 - - [10/Mar/2024 04:44:02] \"POST /generate_flashcards/ HTTP/1.1\" 404 -\n",
      "192.168.29.74 - - [10/Mar/2024 04:44:24] \"POST /generate_flashcards/ HTTP/1.1\" 404 -\n",
      "[2024-03-10 04:53:44,127] ERROR in app: Exception on /generate_flashcards [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Temp\\ipykernel_16636\\4287214555.py\", line 136, in generate_flashcards\n",
      "    if 'candidates' in model_answer[0] and 'content' in model_answer[0]['candidates'][0] and 'parts' in model_answer[0]['candidates'][0]['content'] and 'text' in model_answer[0]['candidates'][0]['content']['parts'][0]:\n",
      "TypeError: 'Response' object is not subscriptable\n",
      "127.0.0.1 - - [10/Mar/2024 04:53:44] \"POST /generate_flashcards HTTP/1.1\" 500 -\n",
      "[2024-03-10 04:54:03,106] ERROR in app: Exception on /generate_flashcards [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Temp\\ipykernel_16636\\4287214555.py\", line 136, in generate_flashcards\n",
      "    if 'candidates' in model_answer[0] and 'content' in model_answer[0]['candidates'][0] and 'parts' in model_answer[0]['candidates'][0]['content'] and 'text' in model_answer[0]['candidates'][0]['content']['parts'][0]:\n",
      "TypeError: 'Response' object is not subscriptable\n",
      "127.0.0.1 - - [10/Mar/2024 04:54:03] \"POST /generate_flashcards HTTP/1.1\" 500 -\n",
      "[2024-03-10 05:18:26,169] ERROR in app: Exception on /generate_flashcards [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2529, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\Fabiha\\AppData\\Local\\Temp\\ipykernel_16636\\4287214555.py\", line 136, in generate_flashcards\n",
      "    if 'candidates' in model_answer[0] and 'content' in model_answer[0]['candidates'][0] and 'parts' in model_answer[0]['candidates'][0]['content'] and 'text' in model_answer[0]['candidates'][0]['content']['parts'][0]:\n",
      "TypeError: 'Response' object is not subscriptable\n",
      "192.168.29.74 - - [10/Mar/2024 05:18:26] \"POST /generate_flashcards HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "from flask import Flask, request, jsonify\n",
    "from google.cloud import storage, speech\n",
    "from google.oauth2 import service_account\n",
    "import googleapiclient.discovery\n",
    "import torchaudio\n",
    "from googletrans import Translator\n",
    "import json\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Path to the service account JSON file\n",
    "client_file = \"sa.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(client_file)\n",
    "service = googleapiclient.discovery.build('speech', 'v1', credentials=credentials)\n",
    "storage_client = storage.Client.from_service_account_json(client_file)\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "def generate_model_answer(prompt):\n",
    "    # Specify the URL for the model endpoint\n",
    "    url = \"https://us-central1-aiplatform.googleapis.com/v1/projects/nitthack/locations/us-central1/publishers/google/models/gemini-1.0-pro:streamGenerateContent\"\n",
    "    # Send a POST request with the JSON data\n",
    "    headers = {\n",
    "        \"Authorization\": os.process.GOOGLE_AUTH,  # Replace with your actual access token\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\"\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=prompt)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return response\n",
    "\n",
    "# Helper function to translate a word\n",
    "def translate_word(word: str, source_lang: str, target_lang: str = 'en'):\n",
    "    from deep_translator import GoogleTranslator\n",
    "    res = GoogleTranslator(source=source_lang, target=target_lang).translate(word) \n",
    "    return res\n",
    "\n",
    "\n",
    "# Endpoint to handle audio file upload and transcription\n",
    "@app.route(\"/upload_and_transcribe/\", methods=[\"POST\"])\n",
    "def upload_and_transcribe():\n",
    "    audio_file = request.files[\"audio_file\"]\n",
    "    gcs_blob = ''.join(random.choices(string.ascii_lowercase, k=5))\n",
    "    audio_file.save(f\"{gcs_blob}.wav\")\n",
    "    r = torchaudio.info(f\"{gcs_blob}.wav\")\n",
    "    bucket = storage_client.get_bucket('speechstoragebucketsamsung')\n",
    "    blob = bucket.blob(gcs_blob)\n",
    "    blob.upload_from_filename(f\"{gcs_blob}.wav\", content_type=\"audio/wav\")\n",
    "    uri = f'gs://speechstoragebucketsamsung/{gcs_blob}'\n",
    "\n",
    "    config = {\n",
    "        \"encoding\": \"LINEAR16\",\n",
    "        \"languageCode\": \"en-US\",\n",
    "        \"enableWordTimeOffsets\": True,\n",
    "        \"sampleRateHertz\" : r.sample_rate,\n",
    "        \"audioChannelCount\" : r.num_channels,\n",
    "    }\n",
    "\n",
    "    body = {\n",
    "        \"config\": config,\n",
    "        \"audio\": {\n",
    "            \"uri\": uri\n",
    "        }\n",
    "    }\n",
    "\n",
    "    service_request = service.speech().longrunningrecognize(body=body)\n",
    "    operation = service_request.execute()\n",
    "\n",
    "    name = operation['name']\n",
    "    service_request = service.operations().get(name=name)\n",
    "    while True:\n",
    "        print('Waiting for server processing...')\n",
    "        time.sleep(1)\n",
    "        response = service_request.execute()\n",
    "        if 'done' in response and response['done']:\n",
    "            break\n",
    "\n",
    "    transcriptions = []\n",
    "    for result in response['response']['results']:\n",
    "        transcriptions.append(result['alternatives'][0]['transcript'])\n",
    "\n",
    "    return jsonify(transcriptions)\n",
    "\n",
    "\n",
    "@app.route(\"/translate/\", methods=[\"POST\"])\n",
    "def translate_word_endpoint():\n",
    "    data = request.json\n",
    "    if not data:\n",
    "        return jsonify({\"error\": \"No JSON data provided\"}), 400\n",
    "    \n",
    "    word = data.get(\"word\")\n",
    "    source_lang = data.get(\"source_lang\")\n",
    "    target_lang = data.get(\"target_lang\", \"en\")\n",
    "    \n",
    "    if not word or not source_lang:\n",
    "        return jsonify({\"error\": \"Missing required fields: 'word' and 'source_lang'\"}), 400\n",
    "\n",
    "    translated_word = translate_word(word, source_lang, target_lang)\n",
    "    return jsonify({\"translated_word\": translated_word})\n",
    "\n",
    "@app.route(\"/generate_flashcards\", methods=[\"POST\"])\n",
    "def generate_flashcards():\n",
    "    data = request.json\n",
    "    transcript = data.get(\"transcript\")\n",
    "\n",
    "    # Format the prompt JSON data\n",
    "    prompt_json = {\n",
    "        \"contents\": {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": {\n",
    "                \"text\": f'Using the transcript as context, generate 5 flashcards for the given transcript, encase each single transcript in *** symbols. The transcript is {transcript}'\n",
    "            }\n",
    "        },\n",
    "        \"generation_config\": {\n",
    "            \"temperature\": 0.6,\n",
    "            \"topP\": 1.0,\n",
    "            \"maxOutputTokens\": 5192\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Convert the prompt JSON data to a string\n",
    "    prompt_json_str = json.dumps(prompt_json)\n",
    "\n",
    "    # Call the method with the prompt JSON\n",
    "    model_answer = generate_model_answer(prompt_json_str)\n",
    "\n",
    "    # Check if the response has the expected structure\n",
    "    if 'candidates' in model_answer[0] and 'content' in model_answer[0]['candidates'][0] and 'parts' in model_answer[0]['candidates'][0]['content'] and 'text' in model_answer[0]['candidates'][0]['content']['parts'][0]:\n",
    "        flashcards_text = model_answer[0]['candidates'][0]['content']['parts'][0]['text']\n",
    "        return jsonify({\"flashcards_text\": flashcards_text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to generate flashcards\"})\n",
    "\n",
    "@app.route(\"/generate_quiz\",methods = [\"POST\"])\n",
    "def generate_quiz():\n",
    "    data = request.json\n",
    "    transcript = data.get(\"flashcards\")\n",
    "\n",
    "    # Format the prompt JSON data\n",
    "    prompt_json = {\n",
    "        \"contents\": {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": {\n",
    "                \"text\": f'Using the flashcards as context, generate 2 quiz questions for the given flashcards, encase each single question in *** symbols. The transcript is {transcript}'\n",
    "            }\n",
    "        },\n",
    "        \"generation_config\": {\n",
    "            \"temperature\": 0.6,\n",
    "            \"topP\": 1.0,\n",
    "            \"maxOutputTokens\": 5192\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Convert the prompt JSON data to a string\n",
    "    prompt_json_str = json.dumps(prompt_json)\n",
    "\n",
    "    # Call the method with the prompt JSON\n",
    "    model_answer = generate_model_answer(prompt_json_str)\n",
    "\n",
    "    # Check if the response has the expected structure\n",
    "    if 'candidates' in model_answer[0] and 'content' in model_answer[0]['candidates'][0] and 'parts' in model_answer[0]['candidates'][0]['content'] and 'text' in model_answer[0]['candidates'][0]['content']['parts'][0]:\n",
    "        flashcards_text = model_answer[0]['candidates'][0]['content']['parts'][0]['text']\n",
    "        return jsonify({\"flashcards_text\": flashcards_text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to generate flashcards\"})\n",
    "@app.route(\"/feedback\",methods = [\"POST\"])\n",
    "def evaluate():\n",
    "    data = request.json\n",
    "    questions = data.get(\"questions\")\n",
    "    answer = data.get(\"answers\")\n",
    "    # Format the prompt JSON data\n",
    "    prompt_json = {\n",
    "        \"contents\": {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": {\n",
    "                \"text\": f'Using the questions as context,give your feedback on the answers submitted as {answer} to the questions {questions}'\n",
    "            }\n",
    "        },\n",
    "        \"generation_config\": {\n",
    "            \"temperature\": 0.6,\n",
    "            \"topP\": 1.0,\n",
    "            \"maxOutputTokens\": 5192\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Convert the prompt JSON data to a string\n",
    "    prompt_json_str = json.dumps(prompt_json)\n",
    "\n",
    "    # Call the method with the prompt JSON\n",
    "    model_answer = generate_model_answer(prompt_json_str)\n",
    "\n",
    "    # Check if the response has the expected structure\n",
    "    if 'candidates' in model_answer[0] and 'content' in model_answer[0]['candidates'][0] and 'parts' in model_answer[0]['candidates'][0]['content'] and 'text' in model_answer[0]['candidates'][0]['content']['parts'][0]:\n",
    "        flashcards_text = model_answer[0]['candidates'][0]['content']['parts'][0]['text']\n",
    "        return jsonify({\"flashcards_text\": flashcards_text})\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Failed to generate flashcards\"})\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3bf29ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'candidates': [{'content': {'role': 'model', 'parts': [{'text': \"Greetings! My name is [Your Name], and I'm a highly motivated and results-oriented individual with a passion for [Your Field of Interest].\"}]}, 'safetyRatings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.053206205, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.059210256}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.07531231, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.06348236}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.053107906, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.039121646}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.27973008, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.12896329}]}]}, {'candidates': [{'content': {'role': 'model', 'parts': [{'text': ' With a strong foundation in [Your Skills], I am eager to leverage my expertise to make a meaningful contribution to your organization.\\n\\nThroughout my career'}]}, 'safetyRatings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.0433658, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.04509957}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.053899158, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.049313594}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.05291181, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.024987796}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.12421302, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.04733772}]}]}, {'candidates': [{'content': {'role': 'model', 'parts': [{'text': ', I have consistently exceeded expectations in [Your Responsibilities]. My ability to [Your Key Strengths] has enabled me to deliver exceptional outcomes in various projects. I am particularly adept at [Your Specific Skills], which I have honed through [Your Experience].\\n\\nBeyond my technical abilities'}]}, 'safetyRatings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.03527755, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.042009056}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.049313594, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.027585283}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.06221698, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.027795624}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.11736965, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.045692034}]}]}, {'candidates': [{'content': {'role': 'model', 'parts': [{'text': ', I am a highly collaborative and effective communicator. I am passionate about building strong relationships and working closely with teams to achieve shared goals. I am also a proactive problem-solver and am always seeking opportunities to improve processes and drive innovation.\\n\\nI am confident that my skills and experience align perfectly with the requirements of this role. I'}]}, 'safetyRatings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.025130948, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.029367855}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.029986508, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.025035424}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.04689926, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.021491764}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.09721884, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.03442355}]}]}, {'candidates': [{'content': {'role': 'model', 'parts': [{'text': ' am eager to join your team and contribute to the success of your organization. Thank you for considering my application. I look forward to the opportunity to discuss my qualifications further and demonstrate how I can add value to your team.'}]}, 'finishReason': 'STOP', 'safetyRatings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.02964751, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.039121646}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.030967519, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.036977552}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.04681203, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.02224367}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'probabilityScore': 0.07613248, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severityScore': 0.033907957}], 'citationMetadata': {'citations': [{'startIndex': 1010, 'endIndex': 1143, 'uri': 'https://thisresumedoesnotexist.com/resume/katie-holmes/'}]}}], 'usageMetadata': {'promptTokenCount': 6, 'candidatesTokenCount': 225, 'totalTokenCount': 231}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example prompt JSON data\n",
    "prompt_json = \"\"\"\n",
    "{\n",
    "  \"contents\": {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": {\n",
    "        \"text\": \"Give me an intro about yourself\"\n",
    "    }\n",
    "  },\n",
    "\n",
    "  \"generation_config\": {\n",
    "    \"temperature\": 0.6,\n",
    "    \"topP\": 1.0,\n",
    "    \"maxOutputTokens\": 5192\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Call the method with the prompt JSON\n",
    "model_answer = generate_model_answer(prompt_json)\n",
    "print(model_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "329ebd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings! My name is [Your Name], and I'm a highly motivated and results-oriented individual with a passion for [Your Field of Interest].\n"
     ]
    }
   ],
   "source": [
    "print(model_answer[0]['candidates'][0]['content']['parts'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2272c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
